{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPutz6A7Zvf5AS53dpkMCmW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17f501bf3487414baf8f64e14e7890a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_824265d9236545f7a0503236ee7d1d27",
              "IPY_MODEL_8196177a52d445bebcc7d4f3ff8e0703",
              "IPY_MODEL_7aadcf8dc82144c5a81b10f617b8686a"
            ],
            "layout": "IPY_MODEL_016fb6b5b73f4ecf84ecfdd5d228d3b7"
          }
        },
        "824265d9236545f7a0503236ee7d1d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2501fb2b5a2843d2858f32f3ec261a9e",
            "placeholder": "​",
            "style": "IPY_MODEL_7b120ecf7f3f4535a954b2e30db4d980",
            "value": "  0%"
          }
        },
        "8196177a52d445bebcc7d4f3ff8e0703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a22ad9534c040a28c10522d04f728da",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_351700ee15094fb1835fc3c7f896e35e",
            "value": 0
          }
        },
        "7aadcf8dc82144c5a81b10f617b8686a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55eab2df550b46a8bb215cee6ed37967",
            "placeholder": "​",
            "style": "IPY_MODEL_026d9483f5de471cbd800e19dc658892",
            "value": " 0/10 [00:00&lt;?, ?it/s]"
          }
        },
        "016fb6b5b73f4ecf84ecfdd5d228d3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2501fb2b5a2843d2858f32f3ec261a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b120ecf7f3f4535a954b2e30db4d980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a22ad9534c040a28c10522d04f728da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351700ee15094fb1835fc3c7f896e35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55eab2df550b46a8bb215cee6ed37967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026d9483f5de471cbd800e19dc658892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35658e120bef4cec95e916570bb81118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbcf838a87a442c2b213d370cf813e2a",
              "IPY_MODEL_161e61c5155144288e0a33fb6e8a06f8",
              "IPY_MODEL_98ae2c27cc564335849273f6671b2547"
            ],
            "layout": "IPY_MODEL_68d3d8d761224f148850b79ee851368f"
          }
        },
        "cbcf838a87a442c2b213d370cf813e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad22d9fc7054e368541597ae3a93e49",
            "placeholder": "​",
            "style": "IPY_MODEL_34c89c6a57414b0ab40ccb915ab2ba45",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "161e61c5155144288e0a33fb6e8a06f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1bc5edf751d414388859548f9ae0211",
            "max": 3513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14dfffb653db49b8a70d2e3fc038d511",
            "value": 3513
          }
        },
        "98ae2c27cc564335849273f6671b2547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06116d0a005c499ea189715f8c71c996",
            "placeholder": "​",
            "style": "IPY_MODEL_1721350797724f4e92a708dfd0781f7c",
            "value": " 3.51k/3.51k [00:00&lt;00:00, 364kB/s]"
          }
        },
        "68d3d8d761224f148850b79ee851368f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad22d9fc7054e368541597ae3a93e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c89c6a57414b0ab40ccb915ab2ba45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1bc5edf751d414388859548f9ae0211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14dfffb653db49b8a70d2e3fc038d511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06116d0a005c499ea189715f8c71c996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1721350797724f4e92a708dfd0781f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9772ded2a4f4d76b2a853a027c7aa26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98a5caf3b69e4d72b48cc85c4ce5b10e",
              "IPY_MODEL_8ff41d05ab6842449e41cfb9fec6ff3a",
              "IPY_MODEL_14e9b39573d84df581e12dd5530679c7"
            ],
            "layout": "IPY_MODEL_a40fa98297e446dcbb3ee9a71953cc48"
          }
        },
        "98a5caf3b69e4d72b48cc85c4ce5b10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2490a360ce4a8c8021f827ef9be4d2",
            "placeholder": "​",
            "style": "IPY_MODEL_fe641a79b1174b1dba6d84756c4c2ea8",
            "value": "tokenizer.json: 100%"
          }
        },
        "8ff41d05ab6842449e41cfb9fec6ff3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ce7e0f15ef44b6a18243a91a268a2d",
            "max": 3314725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc0d09bf785e43e8b6d5cabc8d40a3c1",
            "value": 3314725
          }
        },
        "14e9b39573d84df581e12dd5530679c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ae9e8a98eb7414486a69d06be01eb7f",
            "placeholder": "​",
            "style": "IPY_MODEL_3f2ebd2608eb493f9d5a4db939948f07",
            "value": " 3.31M/3.31M [00:00&lt;00:00, 39.3MB/s]"
          }
        },
        "a40fa98297e446dcbb3ee9a71953cc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2490a360ce4a8c8021f827ef9be4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe641a79b1174b1dba6d84756c4c2ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40ce7e0f15ef44b6a18243a91a268a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0d09bf785e43e8b6d5cabc8d40a3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ae9e8a98eb7414486a69d06be01eb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2ebd2608eb493f9d5a4db939948f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moosunny/Transformer_Translator/blob/main/Seq2Seq_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4qzFD5FVerS",
        "outputId": "b0c7a0e7-a444-4768-f109-3f7e548a07bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598,
          "referenced_widgets": [
            "35658e120bef4cec95e916570bb81118",
            "cbcf838a87a442c2b213d370cf813e2a",
            "161e61c5155144288e0a33fb6e8a06f8",
            "98ae2c27cc564335849273f6671b2547",
            "68d3d8d761224f148850b79ee851368f",
            "3ad22d9fc7054e368541597ae3a93e49",
            "34c89c6a57414b0ab40ccb915ab2ba45",
            "e1bc5edf751d414388859548f9ae0211",
            "14dfffb653db49b8a70d2e3fc038d511",
            "06116d0a005c499ea189715f8c71c996",
            "1721350797724f4e92a708dfd0781f7c",
            "a9772ded2a4f4d76b2a853a027c7aa26",
            "98a5caf3b69e4d72b48cc85c4ce5b10e",
            "8ff41d05ab6842449e41cfb9fec6ff3a",
            "14e9b39573d84df581e12dd5530679c7",
            "a40fa98297e446dcbb3ee9a71953cc48",
            "7d2490a360ce4a8c8021f827ef9be4d2",
            "fe641a79b1174b1dba6d84756c4c2ea8",
            "40ce7e0f15ef44b6a18243a91a268a2d",
            "dc0d09bf785e43e8b6d5cabc8d40a3c1",
            "6ae9e8a98eb7414486a69d06be01eb7f",
            "3f2ebd2608eb493f9d5a4db939948f07"
          ]
        },
        "id": "LixDt3ZkVHtV",
        "outputId": "92a3c9f6-436a-4c08-a6df-11a98017362a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35658e120bef4cec95e916570bb81118"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9772ded2a4f4d76b2a853a027c7aa26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         대분류 소분류                            상황  Set Nr.  발화자  \\\n",
              "0       비즈니스  회의                       의견 교환하기        1  A-1   \n",
              "1       비즈니스  회의                       의견 교환하기        1  B-1   \n",
              "2       비즈니스  회의                       의견 교환하기        1  A-2   \n",
              "3       비즈니스  회의                       의견 교환하기        1  B-2   \n",
              "4       비즈니스  회의                       의견 교환하기        2  A-1   \n",
              "...      ...  ..                           ...      ...  ...   \n",
              "99995  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    24999  B-2   \n",
              "99996  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  A-1   \n",
              "99997  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  B-1   \n",
              "99998  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  A-2   \n",
              "99999  여행/쇼핑  쇼핑  계산/포장/배달 (계산 장소 문의, 계산 오류 등)    25000  B-2   \n",
              "\n",
              "                                             원문  \\\n",
              "0                   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
              "1                    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
              "2                  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
              "3                   네, 제가 연락해서 주문량을 2배로 늘리겠습니다.   \n",
              "4                   지난 회의 마지막에 논의했던 안건을 다시 볼까요?   \n",
              "...                                         ...   \n",
              "99995        저희가 가격표 배치를 잘못해서 혼동을 드렸나 봐요, 죄송해요.   \n",
              "99996                 백화점 포인트로 계산하고 싶은데, 가능한가요?   \n",
              "99997                 네, 물론이죠, 전화번호 입력해주시면 됩니다.   \n",
              "99998              입력했어요, 전액 백화점 포인트로 결제하고 싶어요.   \n",
              "99999  죄송하지만 포인트 제외한 차액 15,000원은 따로 결제해주셔야 합니다.   \n",
              "\n",
              "                                                     번역문  \n",
              "0      How is the market's reaction to the newly rele...  \n",
              "1      The sales increase is faster than the previous...  \n",
              "2      Then, we'll have to call the manufacturer and ...  \n",
              "3      Sure, I'll make a call and double the volume o...  \n",
              "4      Shall we take a look at the issues we discusse...  \n",
              "...                                                  ...  \n",
              "99995  It seems that we didn't place the price tags c...  \n",
              "99996       Can I pay using the department store points?  \n",
              "99997  Yes, of course, you just need to enter your ph...  \n",
              "99998  I entered it, I want to pay it with all the de...  \n",
              "99999  I'm sorry, but you need to make a separate pay...  \n",
              "\n",
              "[100000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7622de05-d8bf-4d50-a2d1-5c4aa1f27026\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>대분류</th>\n",
              "      <th>소분류</th>\n",
              "      <th>상황</th>\n",
              "      <th>Set Nr.</th>\n",
              "      <th>발화자</th>\n",
              "      <th>원문</th>\n",
              "      <th>번역문</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>비즈니스</td>\n",
              "      <td>회의</td>\n",
              "      <td>의견 교환하기</td>\n",
              "      <td>1</td>\n",
              "      <td>A-1</td>\n",
              "      <td>이번 신제품 출시에 대한 시장의 반응은 어떤가요?</td>\n",
              "      <td>How is the market's reaction to the newly rele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>비즈니스</td>\n",
              "      <td>회의</td>\n",
              "      <td>의견 교환하기</td>\n",
              "      <td>1</td>\n",
              "      <td>B-1</td>\n",
              "      <td>판매량이 지난번 제품보다 빠르게 늘고 있습니다.</td>\n",
              "      <td>The sales increase is faster than the previous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>비즈니스</td>\n",
              "      <td>회의</td>\n",
              "      <td>의견 교환하기</td>\n",
              "      <td>1</td>\n",
              "      <td>A-2</td>\n",
              "      <td>그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.</td>\n",
              "      <td>Then, we'll have to call the manufacturer and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>비즈니스</td>\n",
              "      <td>회의</td>\n",
              "      <td>의견 교환하기</td>\n",
              "      <td>1</td>\n",
              "      <td>B-2</td>\n",
              "      <td>네, 제가 연락해서 주문량을 2배로 늘리겠습니다.</td>\n",
              "      <td>Sure, I'll make a call and double the volume o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>비즈니스</td>\n",
              "      <td>회의</td>\n",
              "      <td>의견 교환하기</td>\n",
              "      <td>2</td>\n",
              "      <td>A-1</td>\n",
              "      <td>지난 회의 마지막에 논의했던 안건을 다시 볼까요?</td>\n",
              "      <td>Shall we take a look at the issues we discusse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>여행/쇼핑</td>\n",
              "      <td>쇼핑</td>\n",
              "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
              "      <td>24999</td>\n",
              "      <td>B-2</td>\n",
              "      <td>저희가 가격표 배치를 잘못해서 혼동을 드렸나 봐요, 죄송해요.</td>\n",
              "      <td>It seems that we didn't place the price tags c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>여행/쇼핑</td>\n",
              "      <td>쇼핑</td>\n",
              "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
              "      <td>25000</td>\n",
              "      <td>A-1</td>\n",
              "      <td>백화점 포인트로 계산하고 싶은데, 가능한가요?</td>\n",
              "      <td>Can I pay using the department store points?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>여행/쇼핑</td>\n",
              "      <td>쇼핑</td>\n",
              "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
              "      <td>25000</td>\n",
              "      <td>B-1</td>\n",
              "      <td>네, 물론이죠, 전화번호 입력해주시면 됩니다.</td>\n",
              "      <td>Yes, of course, you just need to enter your ph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>여행/쇼핑</td>\n",
              "      <td>쇼핑</td>\n",
              "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
              "      <td>25000</td>\n",
              "      <td>A-2</td>\n",
              "      <td>입력했어요, 전액 백화점 포인트로 결제하고 싶어요.</td>\n",
              "      <td>I entered it, I want to pay it with all the de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>여행/쇼핑</td>\n",
              "      <td>쇼핑</td>\n",
              "      <td>계산/포장/배달 (계산 장소 문의, 계산 오류 등)</td>\n",
              "      <td>25000</td>\n",
              "      <td>B-2</td>\n",
              "      <td>죄송하지만 포인트 제외한 차액 15,000원은 따로 결제해주셔야 합니다.</td>\n",
              "      <td>I'm sorry, but you need to make a separate pay...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7622de05-d8bf-4d50-a2d1-5c4aa1f27026')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7622de05-d8bf-4d50-a2d1-5c4aa1f27026 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7622de05-d8bf-4d50-a2d1-5c4aa1f27026');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-859cb27a-ea7d-4cca-a203-1363562915c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-859cb27a-ea7d-4cca-a203-1363562915c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-859cb27a-ea7d-4cca-a203-1363562915c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_09c53c21-2dbb-4c53-912f-111d3e105402\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09c53c21-2dbb-4c53-912f-111d3e105402 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"\\ub300\\ubd84\\ub958\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\uc77c\\uc0c1\\ub300\\ud654\",\n          \"\\uc5ec\\ud589/\\uc1fc\\ud551\",\n          \"\\uc758\\ud559\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc18c\\ubd84\\ub958\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 59,\n        \"samples\": [\n          \"\\ud68c\\uc758\",\n          \"\\uc778\\uc0ac\",\n          \"\\ubd80\\uc11c\\ubcc4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc0c1\\ud669\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2779,\n        \"samples\": [\n          \"\\ubc30\\uc1a1 \\ub3c4\\ucc29 \\uc77c\\uc790\\uac00 \\uad81\\uae08\\ud55c \\uc0c1\\ud669\",\n          \"\\uc1a1\\ubcc4\\ud68c\\uac00 \\uc5b8\\uc81c\\uc778\\uc9c0 \\ubb3c\\uc5b4\\ubcf4\\ub294 \\uc0c1\\ud669\",\n          \"\\ud654\\uc7ac \\uc0c1\\ud669, \\uc2e0\\uace0, \\uae30\\ud0c0 \\uc7ac\\ub09c \\uc0c1\\ud669 (\\ud0dc\\ud48d, \\ud64d\\uc218, \\uc9c0\\uc9c4 \\ub4f1)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Set Nr.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7216,\n        \"min\": 1,\n        \"max\": 25000,\n        \"num_unique_values\": 25000,\n        \"samples\": [\n          6869,\n          24017,\n          9669\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubc1c\\ud654\\uc790\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"B-1\",\n          \"B-2\",\n          \"A-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc6d0\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99987,\n        \"samples\": [\n          \"3\\uc77c \\ub4a4\\uba74 \\uad1c\\ucc2e\\uc740\\ub370, \\uba87 \\ubc15 \\uba70\\uce60\\ub85c \\uac00\\ub294 \\uc0c1\\ud488\\uc778\\uac00\\uc694?\",\n          \"\\ub124, \\uc5b4\\uc81c \\uc774 \\uc2e0\\uc6a9\\uce74\\ub4dc\\ub85c \\uacb0\\uc81c\\ud588\\uc5c8\\uc2b5\\ub2c8\\ub2e4.\",\n          \"\\uad6c\\ub9e4\\ud558\\uc2e0 \\uc9c0 \\ud558\\ub8e8\\ubc16\\uc5d0 \\uc9c0\\ub098\\uc9c0 \\uc54a\\uc558\\ub2e4\\uba74 \\ubb3c\\ub860 \\uac00\\ub2a5\\ud569\\ub2c8\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ubc88\\uc5ed\\ubb38\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99916,\n        \"samples\": [\n          \"If the company understands the circumstances, the contract is terminated immediately.\",\n          \"You used a coupon and got a 10 percent discount.\",\n          \"You are right, so please take a coffee inside of my bag and hand it to me.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from transformers import MarianMTModel, MarianTokenizer, AutoTokenizer # MT: Machine Translation\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import math, random\n",
        "\n",
        "# 한국어 토크나이저 활용(upstage)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"upstage/solar-1-mini-tokenizer\")\n",
        "# 패딩을 오른쪽으로 설정\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "\n",
        "# 한국어-영어 대화체 데이터 다운로드(link:)\n",
        "data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Transformer_Translation/2_대화체.xlsx')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eos_idx = tokenizer.eos_token_ids\n",
        "pad_idx = tokenizer.pad_token_ids\n",
        "unk_idx = tokenizer.unk_token_ids\n",
        "\n",
        "\n",
        "# eos token과 pad 토큰의 인덱스가 동일함을 확인 -> unk 토큰을 활용한 문장 패딩 수행\n",
        "print(eos_idx)\n",
        "print(pad_idx)\n",
        "print(unk_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsvVZ0Fw850",
        "outputId": "1835d7c2-99ee-4874-f11d-3c9ac0102702"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "print(tokenizer.pad_token)\n",
        "\n",
        "pad_idx = tokenizer.pad_token_id\n",
        "print(pad_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NTLGN9OxMqT",
        "outputId": "1f507ae0-ea05-45b0-9723-a08b1a65751c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<unk>\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터 모음\n",
        "max_len = 100\n",
        "batch_size = 128\n",
        "vocab_size = tokenizer.vocab_size # 64000개\n",
        "\n",
        "EPOCH = 15\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "embedding_dim = 512"
      ],
      "metadata": {
        "id": "z3cRxKkO9nL1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data.loc[idx, \"원문\"], self.data.loc[idx, \"번역문\"]\n",
        "\n",
        "custom_DS = CustomDataset(data)\n",
        "print(custom_DS[0])\n",
        "\n",
        "train_DS, val_DS, test_DS = torch.utils.data.random_split(custom_DS, [97000, 2000, 1000])\n",
        "# 논문에서는 450만개 영,독 문장 pair 사용\n",
        "\n",
        "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=batch_size, shuffle=True)\n",
        "val_DL = torch.utils.data.DataLoader(val_DS, batch_size=batch_size, shuffle=True)\n",
        "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(len(train_DS))\n",
        "print(len(val_DS))\n",
        "print(len(test_DS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCEn8KbThBH1",
        "outputId": "d4a4e123-3fd4-4fc5-ff5c-756e64e217fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('이번 신제품 출시에 대한 시장의 반응은 어떤가요?', \"How is the market's reaction to the newly released product?\")\n",
            "97000\n",
            "2000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 5\n",
        "src_text, trg_text  = test_DS[0]\n",
        "print(f\"인덱스:{test_DS.indices[i]}\")\n",
        "print(f\"원문:{src_text}\")\n",
        "print(f\"원문:{trg_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPXotOX57cST",
        "outputId": "d052496b-58c9-4c3e-c2cc-f3f7cb66f0e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인덱스:19871\n",
            "원문:그럼 미안하지만 축의금 좀 대신 전해줄 수 있겠어?\n",
            "원문:Then will you give her the money gift for a celebration on behalf of me?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eos_idx = tokenizer.eos_token_ids\n",
        "print(eos_idx)\n",
        "\n",
        "for src_text, trg_text in train_DL:\n",
        "  print(src_text)\n",
        "  print(trg_text)\n",
        "  print(len(src_text))\n",
        "  print(len(trg_text))\n",
        "\n",
        "  src = tokenizer(src_text, padding = True, truncation=True, max_length=max_len, return_tensors = 'pt', add_special_tokens = False).input_ids\n",
        "  trg_text = [s + tokenizer.eos_token for s in trg_text] # eos token 추가 필요\n",
        "  trg = tokenizer(trg_text, padding = True, truncation=True, max_length=max_len, return_tensors = 'pt', add_special_tokens = True).input_ids\n",
        "\n",
        "  print(src[:2])\n",
        "  print(trg[:2])\n",
        "  print(src.shape)\n",
        "  print(trg.shape)\n",
        "\n",
        "  print(trg[:, -1])\n",
        "  print(tokenizer.decode(trg[trg[:,-1]==pad_idx,:][0]))\n",
        "  print(trg[5, :-1])\n",
        "  print(trg[5, 1:])\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "U0zMRvclxWpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0460b56-80ea-4fd5-8a91-0aae302dce20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "('저는 제 차가 아니면 운전하기 좀 거북해서요.', '그럼 제가 팀장님께 가서 전달을 드리도록 하겠습니다.', '너희는 1차 지명한 신인을 1년 만에 버리는 팀인데?', '그러면 그레이 색상으로 교환처리 해주세요.', '회식하고 오전 회의하고 붙어있으면 꽤 신경 쓰이는 일이네요.', '그 배우가 이번에 감독이랑 싸워서 중간에 하차한대.', '담당하는 직원이 따로 있기 때문에 이곳에서는 불가능합니다.', '진심이세요? 그렇다면 정말 기분 좋네요. 좋게 봐주시니 감사해요.', '학생 한 명과 저, 그리고 어른 한 명이 더 있어요.', '어쩐지 좋은 냄새가 난다고 했는데. 맛있겠다.', '나는 그냥 너 먹고 싶은 거 먹을 테니 알아서 주문해.', '네, 제가 국내 번역 에이전시 통해서 알아보고 말씀드리겠습니다.', '메인 식사 요리는 어떤 메뉴로 준비해 드릴까요?', '매장에서 사용하는 포도씨유로 튀긴 겁니다.', '여기는 너만 온 게 아니라, 다른 사람들이 많이 있잖아.', '오늘 고치시는 분이 오셔서 보시더니 누수가 맞대.', '각각 15,000원씩이니 총 60,000원입니다.', '제가 세탁해야 하는 옷이 있는데 객실에 그냥 두면 될까요?', '아니요. 환불받고 다른 상품으로 구매하고 싶습니다.', '여기서 3층으로 가시면 바로 옆 건물 연결통로가 있어요.', '지난번처럼 샘플을 뒤섞어서 가져오면 주문이 힘들어요.', '캐리어가 1개 없어졌는데, 분실물 접수를 어디서 해야 하나요?', '그래도 그렇지, 너랑 어디 같이 못 다니겠다, 창피해서.', '나 지금 현금 없는데 만 원만 좀 빌려줘라, 내일 줄게.', '그러면 앞머리를 살짝만 넘겨 드릴게요.', '니트는 입어보실 수 없고 이 티셔츠는 입어보실 수 있습니다.', '현재 상영하고 있는 연극 정보를 어디서 얻을 수 있나요?', '이 휴대전화가 아직 약정이 만료되지 않았는데 그게 가능한가요?', '그렇군요. 다른 분에게 부탁해 보겠습니다. 조심해서 다녀오세요.', '이 사진 속 단발은 모양이 동글동글해 보이네요.', '부정적인 반응에 대응할 대비책을 마련하고 있습니다.', '그럼 2송이보다 3송이가 훨씬 좋은 것 아닌가요?', '그거는 누구나 다 할 수 있는 말이고, 우리는 경력직만 뽑거든요.', '말씀해주신 사항 유의하여 배송하도록 하겠습니다.', '지금 확인이 안 되시면, 먼저 결제해드리고 다음에 취소 도와드리도록 할게요.', '진료비가 적게 나온 거 같은데, 왜 이렇게 적게 나온 거죠?', '만약 제가 가지고 들어가면 어떻게 되는지 알 수 있나요?', '보고서 내용 말고 기본정보 입력란에 입허가 현황과 소재지 확인란이 비어 있어요.', '네, 추천해주신 호텔과 음식점도 다녀오면서 행복하게 여행했습니다.', '맞는데 혹시 식사에 문제가 있었나요?', '이렇게 갑자기 추가되면 시간이 촉박하지 않나요?', '응, 이런 공간이라면 애완견들이 뛰어놀 수 있겠다.', '네, 지금 바로 경찰 불러드리도록 하겠습니다.', '그럼 너 차 있으니까, 운전해서 가는 게 제일 좋겠네.', '그리고 쇼핑백도 같이 팔던데, 그거 사면 포장도 해주시는 건가요?', '이 이어폰을 끼고 통역을 들어야 하는 건가요?', '예, 소비자가 서비스 리뷰를 휴대폰으로 남길 수 있더라고요.', '블로그 해요. 여기 매장도 거기서 봤어요.', '능숙도가 A 공장보다 떨어지더라도 C 공장에 오더 일부를 넣는 것이 좋을 것 같아.', '제가 저 분의 보험사 알아내서 전화해 볼 거요.', '그렇군요. 몇 시부터 몇 시까지 이용할 수 있죠?', '저기 방금 내 가방이랑 네 가방이 나온 게 맞지?', '제휴할 때의 혜택과 의무에 대해 잘 인지 시켜준 거야?', '죄송합니다만, 저희 매장에 있는 모자는 여기에 있는 모자가 전부입니다.', '식초랑 겨자도 같이 뿌려서 먹어야겠다, 맛있어.', '해석의 여지가 무궁무진하기 때문에 더 재미있는 것 아닐까?', '우리 어머니가 잘 아시는 떡집이 있는데 거기로 가자.', '프로그래밍에 관심이 많고 배우고 싶어서 지원하게 되었습니다.', '강아지에게만 급여할 수 있는 우유입니까?', '지금 홈페이지에 들어가서 수정할 순 없어?', '놀이공원 맞은편에 대형 마트가 있는데, 그 마트 뒤편에 있습니다.', '저번 달 매출 실적이 너무 안 나왔으니 분발해 주세요.', '호박즙 파우치 뚜껑에서 곰팡이로 보이는 검은색 이물질이 나왔어요.', '그럼 창고 쪽에 있는 주스를 가져오면 교환이 되나요?', '맞아요, 저번에 그 사이트인데, 그때는 경고로 그냥 넘어갔는데, 사이트가 주소도 변경하고서 계속해서 불법 캡처로 이익을 얻고 있는 시스템이라서요.', '알겠어. 식당 앞에서 만날까? 아니면 내가 너 태우러 회사 앞으로 갈까?', '하긴 나도 연결된 줄 모르고 항상 나갔다가 다시 들어갔으니.', '잘 못 먹고 계신 것 같은데, 음식이 맞지 않으십니까?', '퇴원을 원하셔서 허락하긴 했지만, 꼭 통원치료 받으셔야 합니다.', '그것 참 곤란하네요, 그럼 대략 얼마 전에 주문해야 할까요?', '맞아요, 그리고 그 외에 모든 상거래 문서도 더는 실물로 출력하지 않아도 됩니다.', '포크와 나이프가 있는 중국 식당을 알고 있어요.', '여러 번이었도 아마 원가에 대한 양보는 어려웠을 거예요.', '반갑습니다, 해당 업무 담당자가 통화 중인데 부재중 메시지를 남겨드릴까요?', '원래 밥하고 후식은 항상 같이 생각하는 거거든.', '확인해 보니, 오전 회진 후 약을 바꾸셨다고 합니다.', '지금 3분의 2 정도는 완료했고, 나머지는 이번 주 목요일까지 작성할 예정이에요.', '그렇다면 뜯어내고 까는 수밖에 없는 건가 보네요?', '저희가 이렇게 자리를 마련할 수 있게 해주셔서 감사합니다.', '다행이네요, 마지막에는 박스에 넣어주시는 건가요?', '저의 지시에만 잘 따라 주시면 크게 위험할 일이 없을 거예요.', '방수밴드 2팩 하셔서 총 3,000원 결제해드릴게요.', '일주일 전에 염색했는데 어둡게 다시 해야 해요.', '그 정도 돈은 여유 있어요, 어디서 지하철을 타면 될까요?', '나는 정말 박물관에 가고 싶지 않은데, 전혀 흥미가 없어.', '택배사에 있는 레일이 고장 나서 좀 지연되고 있다고 해서요, 내일까지는 도착할 거예요.', '요새는 이런 가죽 소재의 외투가 유행이랍니다.', '요즘 한국에서는 공유 오피스가 인기라고 합니다.', '아까 산에서 넘어졌는데 발목이 너무 부었어요.', '그렇다면 어떻게 취소를 할 수 있나요?', '그럼 어깨 정도까지의 길이면 될까요?', '자신의 가장 큰 장단점이 뭐라고 생각하세요?', '오늘 관람 일정 변경 가능할까요?', '죄송한데, 혹시 토스터 세일이 오늘까지였나요?', '그럼 이번에 건너편 상가에 새로운 콩국수 맛집이 생겼는데 그쪽으로 가시겠어요?', '깜빡하고 지갑을 놓고 왔는데, 제 음식값도 좀 내주시겠습니까?', '무슨 옷이 이래요, 구멍이 두 개나 나 있잖아요!', '2주 뒤에 환율 확인한 후에 환전해도 괜찮을 것 같아요.', '네, 음료 주문 안 하시는 분들도 계셔서 입장료를 받는 거예요.', '그러시군요, 좌석마다 다르지만 보통 12만 원입니다.', '이 삼각 김밥은 오늘 저녁 10시까지만 먹으면 되나요?', '조금 아프지만 조금씩 굽힐 수는 있어요.', '배달원은 로비까지만 들어올 수 있으니 1층으로 내려오셔야 합니다.', '정식 메뉴들에 디저트가 포함되어있어요.', '어제 술을 많이 드신 것 같던데 괜찮으신가요?', '평소보다 왜 생산량이 저조한가요?', '현장 분위기는 좀 어땠는지, 현장은 여전히 바쁘죠?', '그러기엔 사고가 크게 난 것 같은데 대체 무슨 일이에요?', '아마 세미나 시간이 6시여서 그런 것 같아요.', '다양하게 구비되어 있으니 직접 가서 보고 명단에 이름과 호실을 적고 빌려가면 됩니다.', '발이 먼저면 오프사이드 아닌가? 옛날에 그렇게 배웠는데.', '그렇다면 어쩔 수 없지, 다음 주 화요일은 어떤가?', '제가 도로 주행 관련해서 몇 가지 주의사항 얘기했던 거 기억하고 있죠?', '안 들어가도 이 냄비로 예전에 버섯 요리를 했으면 이렇게 되기도 하더라.', '네. 잠시만 기다려주세요. 지금 바로 가져다드리겠습니다.', '네, 그럼 포장된 제품을 상자에 넣어서 보내드리겠습니다.', '공항 지하철에 탑승하고 마지막 역까지 가시면 시내로 가는 버스에 탑승할 수 있습니다.', '현금으로 계산하실 손님은 이쪽으로 와주시기 바랍니다.', '나도 잘 못 하긴 하는데 턱걸이를 하면 운동한 기분이 확 들더라고.', '개인 카드로 어떤 경비를 지출하셨나요?', '그런데 과하게 걸었는지 발목이 심하게 부어서 아프네요.', '블랙 색상이 준비되어 있습니다.', '입고 나오시면 제가 롤 업을 해드릴 테니, 비교해보실 수 있어요.', '박물관 관람을 뺄 수는 있어요.', '이 호텔은 무인 체크인기로 체크인하는구나.', '응. 지금 녹음도 하고 있어. 집에 가서 한 번 들어봐.', '안녕하세요. 광고 회사입니다. 광고 콘셉트에 관해서 회의가 필요합니다.', '혹시 마케팅 전략 회의 시간을 미룰 수 있을까요?')\n",
            "(\"I don't feel comfortable driving if it's not my own car.\", 'Then I will go to inform the team leader.', 'But you are talking about a team that let go the first-rounder rookie after a year.', 'Then please exchange it with a gray color.', 'It is bothersome to have a work dinner followed by a morning meeting.', 'He dropped out of the drama because he got into an argument with the director.', 'It is not possible here because there is another staff in charge.', 'Are you serious? You make me feel great. Thank you.', 'A student, myself and another adult.', 'I thought it smelled good. It must be delicious.', \"I'll just eat whatever you want, so order however you see fit.\", 'Yes, I will let you know after searching through domestic translation agencies.', 'What would you like to have for the main dish?', \"They're fried with grapeseed oil used in our store.\", \"You don't own the place, there's plenty of other onlookers.\", 'The person who fixed it came to see it and confirmed the leak.', \"It's 15,000 won each, so the total would be 60,000 won.\", 'I have a few clothes that need to be washed so should I just leave them in the room?', \"No, I don't want a refund but I don't want to buy a new product.\", 'If you go to the 3rd floor from here, there is a passageway to the next building.', \"It's hard to place an order if you mix the samples up like last time.\", 'One carrier is missing, so where should I report about the lost item?', \"But still, I can't go anywhere with you, you're an embarrassment.\", \"Lend me 10,000 won because I don't have any cash on me and I'll pay you back tomorrow.\", \"Then I'll flip your bangs to the side.\", 'You cannot try on knitwear but you can try this t-shirt on.', 'Where can I get information on the plays that are playing right now?', \"Is that possible even though the arrangement on this cell phone hasn't expired yet?\", \"I see. Then I'll ask another person. Have a safe trip.\", 'The bob in this picture looks round.', \"We're preparing a countermeasure to respond to negative reactions.\", \"Then, aren't the 3 bunches much better than the 2 bunches?\", \"That's something anyone can say, and we are only hiring people with experience.\", 'We will ship to you keeping in mind what you said.', \"If you can't confirm now, we'll let you pay first and then help you cancel.\", 'That sounds way too low, but why?', 'Can I know what will happen if I bring it in?', 'The status of admission and authorization and the location checkbox on the basic information column other than the progress report is missing.', 'We had a great honeymoon visiting the hotels and restaurants you recommended.', 'It was, was there any problem with the meal?', \"Aren't we running out time if it's added all of a sudden like this?\", \"Yes, if it's a place like this, pets can run around and play.\", 'Sure, we will call the police right away.', 'Then since you have a car, it would be best to drive there.', 'I see you sell shopping bags together, will you gift wrap it if I buy it?', 'So should I listen to the interpretation through this earphone?', 'Yes, consumers can leave their service reviews on their phones.', 'Yes, I blog, and I found this restaurant on a blog.', 'I think it would be better to put some of the orders in the factory C even if their proficiency is lower than that of factory A.', \"I'll get his insurance company's name and make a call.\", 'I see. What are the hours?', \"Aren't those my bag and your bag that just came out?\", 'Did you inform them of the benefits and obligations of the partnership?', \"I'm sorry, but these hats are all that there are at our store.\", \"I should eat it with vinegar and mustard added, it's delicious.\", \"Isn't it more fun because there's so much room for interpretation?\", \"There's a rice cake shop my mom knows well, so let's head over there.\", 'I am interested in programming and want to learn about it.', 'Is it the kind of milk that can only be fed to dogs?', \"Can't you go into the website and change it now?\", \"There's a big supermarket in front of the amusement park, we're right behind it.\", \"Our sales for last month didn't turn out very well, so please try harder.\", 'From the lid of the pumpkin juice pouch, black substances that look like mold are found.', 'So if I bring the juice from the warehouse, can I exchange it?', 'Yes, it is, we gave a warning the last time, but they keep on changing their address and get profit from illegal captures.', 'Alright. Shall we meet in front of the restaurant? Or shall I pick you up at your office?', \"Well, I also didn't know it was connected and I always went out and went back in.\", \"I don't think you're eating well, is the food not right for you?\", 'I am discharging you because you wanted to be, but you must come for outpatient treatment.', \"That's a bit of a problem, then how much earlier should I place the order?\", \"Yes, and you don't need to print all other commercial documents as well.\", 'I know a Chinese restaurant with forks and knives.', 'Even if there were many meetings, it would have been hard to get a concession on unit cost.', 'Nice to meet you, but the person in charge of the project is on the phone so would you like me to take a message for him?', 'I always think about rice and dessert together.', 'I checked with him, and he said he did after the morning visit.', \"I've finished two-thirds of it, and I will finish it until this Thursday.\", 'Is there any other way other than ripping it off and installing it then?', 'Thank you for letting us prepare for this meeting.', \"That's nice, do you put them in a box in the end?\", \"As long as you follow my orders, there won't be any big problems.\", 'That would be 3,000 in total.', 'I had my hair dyed a week ago, but I have to get it darker again.', 'I have that amount available, where can I take the subway?', \"I really don't want to go to the museum, I have absolutely no interest.\", 'The rails are out of order at the courier office, it will arrive by tomorrow.', 'Jackets made of leather are rather popular these days.', 'Shared offices are popular in Korea these days.', 'I fell over in the mountains before, and my ankle is all swollen up.', 'Then how can I cancel it?', 'Would a shoulder-length be ok?', 'What do you think your biggest strengths and weaknesses are?', \"Is it possible to change today's tour date?\", \"I'm sorry, but was the sale for the toaster due today?\", 'There is a really good new restaurant with soybean noodles in the building across the street, would you like to go there?', 'I forgot and left my wallet, will you pay for my meal?', 'What kind of clothes is this, there are two holes in it!', 'I think it would be ok to exchange currencies after checking the exchange rate in 2 weeks.', \"Yes, we are charging an entrance fee because some people don't order a drink.\", \"Okay, it's different from seat to seat but it's usually 120,000won.\", 'Is it okay if I eat this triangle gimbap by 10 this evening?', 'It hurts a little, but I can slightly bend it.', 'The delivery person can only come to the lobby, so you have to come down to the 1st floor.', 'All course meals have dessert included.', 'Looks like you had a lot of drinks yesterday, and do you feel okay?', 'Why is production lower than usual?', 'How was the mood on site, is the site still busy?', 'It seems like a huge accident just occurred, what happened?', 'Probably because it started at 6 pm.', 'Various types have been prepared, so you can go yourself and borrow them by writing your name and room number on the list.', \"Isn't it offside when your feet are further forward? That's how I learned it in the past.\", 'Nothing can be done about it now, how about Tuesday next week?', 'You remember the things I told you to be careful of regarding the road test, right?', \"Even if they don't use mushrooms, sometimes I get this reaction if they've used the same pot they used to cook mushrooms.\", 'Yes, hold on a moment. I will bring it to you right away.', 'Okay, then I will put the wrapped product in a box and ship it out.', 'You can get to the city by taking the airport train to the last station, and then taking a bus to the city from there.', \"Please come this way if you're a customer wanting to pay in cash.\", 'I am not good at it either but it feels like I am working out when I do it.', 'What kind of payments did you make with your credit card?', 'But maybe I walked too much because my ankle is severely swollen and it hurts.', 'We have it in black.', \"I'll roll it up when you come out, so you can compare.\", 'We can take out the museum tour.', 'You can check-in by the kiosk at this hotel.', \"Yes. I'm recording now. You can listen to it at home.\", 'Hello, this is an advertising agency. We need to have a meeting on the advertisement concept.', 'Can we postpone the marketing strategy meeting?')\n",
            "128\n",
            "128\n",
            "tensor([[36874, 32053, 48966, 42346, 39322, 32320, 34156, 32221, 58717, 33098,\n",
            "         29517, 28723,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [39558, 36104, 34650, 29747, 38266, 41634, 35027, 29189, 45638, 32572,\n",
            "         46211, 28723,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0]])\n",
            "tensor([[    1,   315,   949, 28742, 28707,  1601,  8450,  7810,   513,   378,\n",
            "         28742, 28713,   459,   586,  1216,  1253, 28723,     2,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [    1,  2479,   315,   622,   576,   298,  5227,   272,  1918,  7059,\n",
            "         28723,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n",
            "torch.Size([128, 37])\n",
            "torch.Size([128, 32])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "<|startoftext|> I don't feel comfortable driving if it's not my own car.<|endoftext|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
            "tensor([    1,   650,  7679,   575,   302,   272, 13792,  1096,   400,  1433,\n",
            "          778,   396,  5270,   395,   272,  6859, 28723,     2,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0])\n",
            "tensor([  650,  7679,   575,   302,   272, 13792,  1096,   400,  1433,   778,\n",
            "          396,  5270,   395,   272,  6859, 28723,     2,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU9VnETYE3iV",
        "outputId": "1499f788-f4e7-4ec4-97d3-e6dcce86a6e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 1000 # Seq2Seq 논문 상으로 1000 Embedding_dim\n",
        "enc_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "dec_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "for src, trg in train_DL:\n",
        "  print(src[0]) # (배치 사이즈, 문장 길이)\n",
        "  print(trg[0])\n",
        "  N = len(train_DL)\n",
        "  src = tokenizer(src, padding = True, truncation = True, max_length = max_len, return_tensors = 'pt', add_special_tokens = False).input_ids\n",
        "  trg = [s + tokenizer.eos_token for s in trg] # eos token 추가 필요\n",
        "  trg = tokenizer(trg, padding = True, truncation = True, max_length = max_len, return_tensors = 'pt', add_special_tokens = True).input_ids\n",
        "  print(src.shape)\n",
        "  print(trg.shape)\n",
        "\n",
        "  ### Encoder Layer\n",
        "  enc_embedded_src = enc_embedding(src)\n",
        "  print(f\"임베딩 후 차원: {enc_embedded_src.shape}\") # (배치 사이즈, 문장 길이, 임베딩 차원)\n",
        "  enc_src = nn.Dropout(0.5)(enc_embedded_src)\n",
        "  print(f\"임베딩 -> Dropout 후 차원: {enc_src.shape}\")\n",
        "  enc_lstm = nn.LSTM(input_size = embedding_dim, hidden_size = 1000, num_layers = 4, dropout = 0.5, batch_first= True)\n",
        "  # encoder output\n",
        "  enc_output, (enc_hidden, enc_cell) = enc_lstm(enc_src)\n",
        "  print(f\"LSTM 레이어 통과 후 차원: {enc_output.shape}\")\n",
        "   # num_layers 만큼 hidden, cell state 출력\n",
        "  print(f\"hidden state 차원: {enc_hidden.shape}\")\n",
        "  print(f\"cell state 차원: {enc_cell.shape}\")\n",
        "\n",
        "  ### Decoder Layer\n",
        "  # input = [batch size]\n",
        "  # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "  # cell = [n layers * n directions, batch size, hidden dim]\n",
        "  # n directions in the decoder will both always be 1, therefore:\n",
        "  # hidden = [n layers, batch size, hidden dim]\n",
        "  # context = [n layers, batch size, hidden dim]\n",
        "  trg = trg.permute(1,0)\n",
        "  dec_input =  trg[0, :]\n",
        "  dec_input = dec_input.unsqueeze(0)\n",
        "  print(dec_input.shape)\n",
        "  # dec_embedded_trg = dec_embedding(trg)\n",
        "  # print(f\"임베딩 후 차원: {dec_embedded_trg.shape}\") # (배치 사이즈, 문장 길이, 임베딩 차원)\n",
        "  # dec_trg = nn.Dropout(0.5)(dec_embedded_trg)\n",
        "  # dec_lstm = nn.LSTM(input_size = , hidden_size = 1000, num_layers = 4, dropout = 0.5, batch_first = True)\n",
        "\n",
        "\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHZH-3PeDt6J",
        "outputId": "afb6a04a-e8dd-4bdf-c068-819671c1d51e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "고객님, 이 가격은 현재 세일 가격이 맞습니다.\n",
            "Sir, this price is the correct sale price right now.\n",
            "torch.Size([128, 27])\n",
            "torch.Size([128, 34])\n",
            "임베딩 후 차원: torch.Size([128, 27, 1000])\n",
            "임베딩 -> Dropout 후 차원: torch.Size([128, 27, 1000])\n",
            "LSTM 레이어 통과 후 차원: torch.Size([128, 27, 1000])\n",
            "hidden state 차원: torch.Size([4, 128, 1000])\n",
            "cell state 차원: torch.Size([4, 128, 1000])\n",
            "torch.Size([1, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src length, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded = [src length, batch size, embedding dim]\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # outputs = [src length, batch size, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # outputs are always from the top hidden layer\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        # input = [batch size]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # n directions in the decoder will both always be 1, therefore:\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # context = [n layers, batch size, hidden dim]\n",
        "        input = input.unsqueeze(0)\n",
        "        # input = [1, batch size]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded = [1, batch size, embedding dim]\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        # output = [seq length, batch size, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [1, batch size, hidden dim]\n",
        "        # hidden = [n layers, batch size, hidden dim]\n",
        "        # cell = [n layers, batch size, hidden dim]\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        assert (\n",
        "            encoder.hidden_dim == decoder.hidden_dim\n",
        "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert (\n",
        "            encoder.n_layers == decoder.n_layers\n",
        "        ), \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio):\n",
        "        # src = [src length, batch size]\n",
        "        # trg = [trg length, batch size]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_length = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[0, :]\n",
        "        # input = [batch size]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden and previous cell states\n",
        "            # receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, hidden dim]\n",
        "            # cell = [n layers, batch size, hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            # input = [batch size]\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "MdFsQHM8CVaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6cNnOd7kWvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "# seed 고정\n",
        "def seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(42)\n",
        "\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self, text, tokenizer, vocab_size, max_length = max_len, embedding_dim=1000):\n",
        "#         self.text = text\n",
        "#         self.tokenizer = tokenizer\n",
        "#         self.max_length = max_length\n",
        "#         self.vocab_size = vocab_size\n",
        "#         self.embedding_dim = embedding_dim\n",
        "#         self.emb = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.text)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#       text = self.text[idx]\n",
        "\n",
        "#       encoding = self.tokenizer(\n",
        "#                                 text,\n",
        "#                                 padding=\"max_length\",\n",
        "#                                 max_length=self.max_length,\n",
        "#                                 truncation= True,\n",
        "#                                 return_tensors=\"pt\"\n",
        "#                                 )\n",
        "#       input_idx = encoding[\"input_ids\"]\n",
        "#       embedded_inputs = self.emb(input_idx)\n",
        "\n",
        "\n",
        "#       return embedded_inputs.squeeze(0) # (1, max_length, emb_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # 패딩을 오른쪽으로 설정\n",
        "# tokenizer.padding_side = \"right\"\n",
        "\n",
        "# # pad token index 설정\n",
        "# tokenizer.pad_token_id = 0  # 패딩 토큰의 인덱스 설정\n",
        "\n",
        "\n",
        "# # source 데이터 분리\n",
        "# train_src = data_kor_list[:89999]\n",
        "# val_src = data_kor_list[90000:94999]\n",
        "# test_src = data_kor_list[9500:]\n",
        "\n",
        "# # target 데이터 분리\n",
        "# train_target = data_eng_list[:89999]\n",
        "# val_target = data_eng_list[90000:94999]\n",
        "# test_target = data_eng_list[95000:]\n",
        "\n",
        "\n",
        "# # 데이터셋 생성\n",
        "# train_src_dataset = CustomDataset(text = train_src, tokenizer = tokenizer,  vocab_size = vocab_size)\n",
        "# val_src_dataset = CustomDataset(text = val_src, tokenizer = tokenizer,  vocab_size = vocab_size)\n",
        "# test_src_dataset = CustomDataset(text = test_src, tokenizer = tokenizer,  vocab_size = vocab_size)\n",
        "\n",
        "# train_input_data = train_data\n",
        "\n",
        "\n",
        "# # train dataloader\n",
        "# train_src_dataloader = DataLoader(train_src_dataset, batch_size=128, shuffle=False)\n",
        "# val_src_dataloader = DataLoader(val_src_dataset, batch_size=128, shuffle=False)\n",
        "# test_src_dataloader = DataLoader(test_src_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "iqUK97SxcCRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target data\n",
        "# train_target_dataset = CustomDataset(text = train_target, tokenizer = tokenizer,  vocab_size = vocab_size)\n",
        "# val_target_dataset = CustomDataset(text = val_target, tokenizer = tokenizer,  vocab_size = vocab_size)\n",
        "# test_target_dataset = CustomDataset(text = test_target, tokenizer = tokenizer,  vocab_size = vocab_size)\n",
        "\n",
        "# train_target_dataloader = DataLoader(train_target_dataset, batch_size=128, shuffle=False)\n",
        "# val_target_dataloader = DataLoader(val_target_dataset, batch_size=128, shuffle=False)\n",
        "# test_target_dataloader = DataLoader(test_target_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "juTX9wpT834g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(tokenizer.get_vocab().items())\n",
        "output_dim = len(tokenizer.get_vocab().items())\n",
        "encoder_embedding_dim = 256\n",
        "decoder_embedding_dim = 256\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "encoder_dropout = 0.5\n",
        "decoder_dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim,\n",
        "    encoder_embedding_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    encoder_dropout,\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_dim,\n",
        "    decoder_embedding_dim,\n",
        "    hidden_dim,\n",
        "    n_layers,\n",
        "    decoder_dropout,\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)"
      ],
      "metadata": {
        "id": "FUcKi5UOkROf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "5be34cfa-1e89-4156-c6f4-997b39ee29f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-99f1da3cd47e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "Ith-9WYjvXFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_dim,\"input_dim\")\n",
        "print(output_dim,\"output_dim\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJWqQpv-VVdk",
        "outputId": "09c9c4d6-8c0a-4d48-d1be-b487805722ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64000 input_dim\n",
            "64000 output_dim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGJLaDAPy1bh",
        "outputId": "42a9b690-7caa-41c4-82f6-33301b999c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 30,426,710 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_index = tokenizer.pad_token_id\n",
        "print(pad_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKtNg9hj6xks",
        "outputId": "40aebbd0-6535-411d-9577-1cf1bd848d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index= pad_index)\n",
        "\n",
        "def train_fn(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        print(batch[\"kor_ids\"].dtype)  # float32/int64/long 확인\n",
        "        print(batch[\"kor_ids\"].min(), batch[\"kor_ids\"].max())  # 범위 체크\n",
        "        print(batch[\"eng_ids\"].min(), batch[\"eng_ids\"].max())  # 범위 체크\n",
        "        print(batch[\"kor_ids\"].device)\n",
        "        src = batch[\"kor_ids\"].to(device).long()\n",
        "        print(src.dtype)\n",
        "        trg = batch[\"eng_ids\"].to(device).long()\n",
        "        print(src.shape)\n",
        "        print(trg.shape)\n",
        "        # src = [src length, batch size]\n",
        "        # trg = [trg length, batch size]\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, teacher_forcing_ratio)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        print(output.shape)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "W4m2g9OY0MSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fn(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            src = batch[\"kor_ids\"].to(device).long()\n",
        "            trg = batch[\"eng_ids\"].to(device).long()\n",
        "            print(src.shape)\n",
        "            print(trg.shape)\n",
        "            # src = [src length, batch size]\n",
        "            # trg = [trg length, batch size]\n",
        "            output = model(src, trg, 0)  # turn off teacher forcing\n",
        "            # output = [trg length, batch size, trg vocab size]\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            print(output.shape)\n",
        "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "            trg = trg[1:].view(-1)\n",
        "            # trg = [(trg length - 1) * batch size]\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "MDhq-fjh4xJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "n_epochs = 10\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    train_loss = train_fn(\n",
        "        model,\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        clip,\n",
        "        teacher_forcing_ratio,\n",
        "        device,\n",
        "    )\n",
        "    valid_loss = evaluate_fn(\n",
        "        model,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        device,\n",
        "    )\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), \"tut1-model.pt\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533,
          "referenced_widgets": [
            "17f501bf3487414baf8f64e14e7890a1",
            "824265d9236545f7a0503236ee7d1d27",
            "8196177a52d445bebcc7d4f3ff8e0703",
            "7aadcf8dc82144c5a81b10f617b8686a",
            "016fb6b5b73f4ecf84ecfdd5d228d3b7",
            "2501fb2b5a2843d2858f32f3ec261a9e",
            "7b120ecf7f3f4535a954b2e30db4d980",
            "1a22ad9534c040a28c10522d04f728da",
            "351700ee15094fb1835fc3c7f896e35e",
            "55eab2df550b46a8bb215cee6ed37967",
            "026d9483f5de471cbd800e19dc658892"
          ]
        },
        "id": "st_koGvh5TKl",
        "outputId": "f3206e92-74b0-4a7f-e4a3-a48ad6f62948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17f501bf3487414baf8f64e14e7890a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "tensor(0) tensor(62733)\n",
            "tensor(0) tensor(28808)\n",
            "cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-f10d35241354>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     train_loss = train_fn(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-138ee4d4c6a5>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eng_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eng_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 범위 체크\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kor_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kor_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eng_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DLgDWVe15Xm1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}